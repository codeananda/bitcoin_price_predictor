{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "```python\n",
    "data = load_data(amount_of_time)\n",
    "processor = Processor()\n",
    "# How to manage training vs inference datasets?\n",
    "processed_dataset = processor.fit_transform(data)\n",
    "model = build_model()\n",
    "# How to do validation dataset?\n",
    "# How to do KFold? Can I put this in a sklearn pipeline?\n",
    "model.fit(processed_dataset)\n",
    "```\n",
    "\n",
    "# Inference\n",
    "```python\n",
    "data = load_data(amount_of_time)\n",
    "processor = Processor()\n",
    "# Should just be 1 batch long (batch length is tuned in training)\n",
    "processed_dataset = processor.fit_transform(data)\n",
    "model = load_model()\n",
    "preds = model.predict(processed_dataset)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_btc_data():\n",
    "    num_seconds_in_8_days = 60 * 60 * 24 * 8\n",
    "    num_milliseconds_in_8_days = num_seconds_in_8_days * 1000\n",
    "\n",
    "    now_ns = str(time.time_ns())\n",
    "    # Take first 13 digits for milliseconds\n",
    "    # Coincap API only accepts milliseconds\n",
    "    now_ms = int(now_ns[:13])\n",
    "    eight_days_ago = now_ms - num_milliseconds_in_8_days\n",
    "\n",
    "    # Get Bitcoin data for last 8 days\n",
    "    url = (\n",
    "        f\"https://api.coincap.io/v2/assets/bitcoin/history?interval=h1\"\n",
    "        # f\"&start={eight_days_ago}&end={now_ms}\"\n",
    "    )\n",
    "\n",
    "    payload = {}\n",
    "    headers = {\"Authorization\": \"Bearer bff099f6-aec1-4e2f-8cec-57f8eea14e27\"}\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    response.raise_for_status()\n",
    "    response.status_code\n",
    "\n",
    "    json_data = response.json()\n",
    "    bitcoin_data = json_data[\"data\"]\n",
    "\n",
    "    df = pd.DataFrame(bitcoin_data)\n",
    "    df = df.loc[:, [\"date\", \"priceUsd\"]]\n",
    "    df.rename(mapper={\"priceUsd\": \"price\"}, inplace=True, axis=1)\n",
    "    df[\"date\"] = df[\"date\"].apply(pd.to_datetime)\n",
    "    df[\"price\"] = df[\"price\"].apply(pd.to_numeric)\n",
    "    df[\"price\"] = df[\"price\"].round(2)\n",
    "    df.sort_values(\"date\", ascending=False, ignore_index=True, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_all_btc_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 1, 2, 3]), array([ 0, -1, -2, -3])]\n",
      "[array([4, 5, 6, 7]), array([-4, -5, -6, -7])]\n",
      "[array([ 8,  9, 10, 11]), array([ -8,  -9, -10, -11])]\n",
      "[array([12, 13, 14, 15]), array([-12, -13, -14, -15])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-13 13:36:10.400047: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "inc_dataset = tf.data.Dataset.range(100)\n",
    "dec_dataset = tf.data.Dataset.range(0, -100, -1)\n",
    "dataset = tf.data.Dataset.zip((inc_dataset, dec_dataset))\n",
    "batched_dataset = dataset.batch(4)\n",
    "\n",
    "for batch in batched_dataset.take(4):\n",
    "  print([arr.numpy() for arr in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ZipDataset shapes: ((), ()), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 -1\n",
      "2 -2\n",
      "3 -3\n"
     ]
    }
   ],
   "source": [
    "for thing in dataset.take(4):\n",
    "    print(thing[0].numpy(), thing[1].numpy())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ecf27939019150eaf754eaa3fa3d26a02c50bfda8c9a7333dada8ff5bafce6b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
